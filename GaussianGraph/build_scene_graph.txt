1. 初始化与数据加载

- 加载训练好的 3D Gaussian 模型 。
- 加载 点云聚类结果 (Leaf Codebook) ，这是之前步骤生成的，将 3D 高斯点划分为了不同的簇（Cluster）。
- 计算每个 3D 簇的 几何统计信息 （中心点坐标、3D 包围盒），使用分位数（5%-95%）来去除离群点干扰。
2. 遍历训练视角 (View Loop)

- 脚本会遍历所有训练视角的图片。
- 读取 2D 语义 ：加载每张图片对应的语言特征 JSON（包含物体检测、类别、描述、关系）和 SAM 分割掩码。
- 渲染 3D 掩码 ：将 3D 聚类投影渲染到当前视角的 2D 平面上，得到 Cluster Mask。
- 2D-3D 匹配 ：通过计算 IoU (交并比) ，将 2D 检测到的物体掩码与渲染出的 3D 聚类掩码进行匹配。如果 IoU > 0.3，则认为它们是同一个物体，并将 2D 的类别和描述信息聚合到对应的 3D 节点上。
- 关系提取 ：解析 2D JSON 中的关系对（如 "chair at table"），找到对应的两个 3D 聚类，并在它们之间建立边。
3. 信息聚合 (Aggregation)

- 类别投票 ：由于一个 3D 物体在不同视角下可能被识别为不同类别，脚本使用 多数投票 (Majority Vote) 机制来确定最终的主类别。
- 描述选择 ：在确定主类别后，从所有相关的描述中选择 最长（最详细） 的一条作为该节点的最终 Caption。
- 关系合并 ：同样对边上的关系描述进行聚合，选择最详细的关系描述。
4. 后处理 (Post-processing)

- 过滤 ：移除类别标记为 "unknown" 的节点。
- 合并节点 ：为了解决过度分割（同一个物体被分成多个簇）的问题，脚本使用了两套合并策略：
  - 激进合并 ：针对背景类（墙、地板、天花板等），只要中心点距离小于 2.5 米就合并。
  - 保守合并 ：针对所有类别，计算 3D 包围盒的重叠率。如果两个节点在 3D 空间中有显著重叠（IoU > 0.2），则合并它们。
- 更新边 ：节点合并后，重新映射边的连接关系，并去除自环和重复边。
5. 结果保存

- 重新计算合并后节点的中心、包围盒和点数。
- 将最终的节点（Nodes）和边（Edges）保存为 scene_graph_{iteration}.json 文件。